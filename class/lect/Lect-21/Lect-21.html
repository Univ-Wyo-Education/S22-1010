<style>
@font-face {
	font-family: octicons-link;
	src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

.markdown-body {
	-ms-text-size-adjust: 100%;
	-webkit-text-size-adjust: 100%;
	line-height: 1.5;
	color: #24292e;
	font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
	font-size: 16px;
	line-height: 1.5;
	word-wrap: break-word;
}

.markdown-body .pl-c {
	color: #6a737d;
}

.markdown-body .pl-c1,
.markdown-body .pl-s .pl-v {
	color: #005cc5;
}

.markdown-body .pl-e,
.markdown-body .pl-en {
	color: #6f42c1;
}

.markdown-body .pl-smi,
.markdown-body .pl-s .pl-s1 {
	color: #24292e;
}

.markdown-body .pl-ent {
	color: #22863a;
}

.markdown-body .pl-k {
	color: #d73a49;
}

.markdown-body .pl-s,
.markdown-body .pl-pds,
.markdown-body .pl-s .pl-pse .pl-s1,
.markdown-body .pl-sr,
.markdown-body .pl-sr .pl-cce,
.markdown-body .pl-sr .pl-sre,
.markdown-body .pl-sr .pl-sra {
	color: #032f62;
}

.markdown-body .pl-v,
.markdown-body .pl-smw {
	color: #e36209;
}

.markdown-body .pl-bu {
	color: #b31d28;
}

.markdown-body .pl-ii {
	color: #fafbfc;
	background-color: #b31d28;
}

.markdown-body .pl-c2 {
	color: #fafbfc;
	background-color: #d73a49;
}

.markdown-body .pl-c2::before {
	content: "^M";
}

.markdown-body .pl-sr .pl-cce {
	font-weight: bold;
	color: #22863a;
}

.markdown-body .pl-ml {
	color: #735c0f;
}

.markdown-body .pl-mh,
.markdown-body .pl-mh .pl-en,
.markdown-body .pl-ms {
	font-weight: bold;
	color: #005cc5;
}

.markdown-body .pl-mi {
	font-style: italic;
	color: #24292e;
}

.markdown-body .pl-mb {
	font-weight: bold;
	color: #24292e;
}

.markdown-body .pl-md {
	color: #b31d28;
	background-color: #ffeef0;
}

.markdown-body .pl-mi1 {
	color: #22863a;
	background-color: #f0fff4;
}

.markdown-body .pl-mc {
	color: #e36209;
	background-color: #ffebda;
}

.markdown-body .pl-mi2 {
	color: #f6f8fa;
	background-color: #005cc5;
}

.markdown-body .pl-mdr {
	font-weight: bold;
	color: #6f42c1;
}

.markdown-body .pl-ba {
	color: #586069;
}

.markdown-body .pl-sg {
	color: #959da5;
}

.markdown-body .pl-corl {
	text-decoration: underline;
	color: #032f62;
}

.markdown-body .octicon {
	display: inline-block;
	vertical-align: text-top;
	fill: currentColor;
}

.markdown-body a {
	background-color: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
	outline-width: 0;
}

.markdown-body strong {
	font-weight: inherit;
}

.markdown-body strong {
	font-weight: bolder;
}

.markdown-body h1 {
	font-size: 2em;
	margin: 0.67em 0;
}

.markdown-body img {
	border-style: none;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre {
	font-family: monospace, monospace;
	font-size: 1em;
}

.markdown-body hr {
	box-sizing: content-box;
	height: 0;
	overflow: visible;
}

.markdown-body input {
	font: inherit;
	margin: 0;
}

.markdown-body input {
	overflow: visible;
}

.markdown-body [type="checkbox"] {
	box-sizing: border-box;
	padding: 0;
}

.markdown-body * {
	box-sizing: border-box;
}

.markdown-body input {
	font-family: inherit;
	font-size: inherit;
	line-height: inherit;
}

.markdown-body a {
	color: #0366d6;
	text-decoration: none;
}

.markdown-body a:hover {
	text-decoration: underline;
}

.markdown-body strong {
	font-weight: 600;
}

.markdown-body hr {
	height: 0;
	margin: 15px 0;
	overflow: hidden;
	background: transparent;
	border: 0;
	border-bottom: 1px solid #dfe2e5;
}

.markdown-body hr::before {
	display: table;
	content: "";
}

.markdown-body hr::after {
	display: table;
	clear: both;
	content: "";
}

.markdown-body table {
	border-spacing: 0;
	border-collapse: collapse;
}

.markdown-body td,
.markdown-body th {
	padding: 0;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
	margin-top: 0;
	margin-bottom: 0;
}

.markdown-body h1 {
	font-size: 32px;
	font-weight: 600;
}

.markdown-body h2 {
	font-size: 24px;
	font-weight: 600;
}

.markdown-body h3 {
	font-size: 20px;
	font-weight: 600;
}

.markdown-body h4 {
	font-size: 16px;
	font-weight: 600;
}

.markdown-body h5 {
	font-size: 14px;
	font-weight: 600;
}

.markdown-body h6 {
	font-size: 12px;
	font-weight: 600;
}

.markdown-body p {
	margin-top: 0;
	margin-bottom: 10px;
}

.markdown-body blockquote {
	margin: 0;
}

.markdown-body ul,
.markdown-body ol {
	padding-left: 0;
	margin-top: 0;
	margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
	x-list-style-type: lower-roman;
	  list-style-type: decimal;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
	list-style-type: lower-alpha;
}

.markdown-body dd {
	margin-left: 0;
}

.markdown-body code {
	font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace;
	font-size: 12px;
}

.markdown-body pre {
	margin-top: 0;
	margin-bottom: 0;
	font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace;
	font-size: 12px;
}

.markdown-body .octicon {
	vertical-align: text-bottom;
}

.markdown-body .pl-0 {
	padding-left: 0 !important;
}

.markdown-body .pl-1 {
	padding-left: 4px !important;
}

.markdown-body .pl-2 {
	padding-left: 8px !important;
}

.markdown-body .pl-3 {
	padding-left: 16px !important;
}

.markdown-body .pl-4 {
	padding-left: 24px !important;
}

.markdown-body .pl-5 {
	padding-left: 32px !important;
}

.markdown-body .pl-6 {
	padding-left: 40px !important;
}

.markdown-body::before {
	display: table;
	content: "";
}

.markdown-body::after {
	display: table;
	clear: both;
	content: "";
}

.markdown-body>*:first-child {
	margin-top: 0 !important;
}

.markdown-body>*:last-child {
	margin-bottom: 0 !important;
}

.markdown-body a:not([href]) {
	color: inherit;
	text-decoration: none;
}

.markdown-body .anchor {
	float: left;
	padding-right: 4px;
	margin-left: -20px;
	line-height: 1;
}

.markdown-body .anchor:focus {
	outline: none;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre {
	margin-top: 0;
	margin-bottom: 16px;
}

.markdown-body hr {
	height: 0.25em;
	padding: 0;
	margin: 24px 0;
	background-color: #e1e4e8;
	border: 0;
}

.markdown-body blockquote {
	padding: 0 1em;
	color: #6a737d;
	border-left: 0.25em solid #dfe2e5;
}

.markdown-body blockquote>:first-child {
	margin-top: 0;
}

.markdown-body blockquote>:last-child {
	margin-bottom: 0;
}

.markdown-body kbd {
	display: inline-block;
	padding: 3px 5px;
	font-size: 11px;
	line-height: 10px;
	color: #444d56;
	vertical-align: middle;
	background-color: #fafbfc;
	border: solid 1px #c6cbd1;
	border-bottom-color: #959da5;
	border-radius: 3px;
	box-shadow: inset 0 -1px 0 #959da5;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
	margin-top: 24px;
	margin-bottom: 16px;
	font-weight: 600;
	line-height: 1.25;
}

.markdown-body h1 .octicon-link,
.markdown-body h2 .octicon-link,
.markdown-body h3 .octicon-link,
.markdown-body h4 .octicon-link,
.markdown-body h5 .octicon-link,
.markdown-body h6 .octicon-link {
	color: #1b1f23;
	vertical-align: middle;
	visibility: hidden;
}

.markdown-body h1:hover .anchor,
.markdown-body h2:hover .anchor,
.markdown-body h3:hover .anchor,
.markdown-body h4:hover .anchor,
.markdown-body h5:hover .anchor,
.markdown-body h6:hover .anchor {
	text-decoration: none;
}

.markdown-body h1:hover .anchor .octicon-link,
.markdown-body h2:hover .anchor .octicon-link,
.markdown-body h3:hover .anchor .octicon-link,
.markdown-body h4:hover .anchor .octicon-link,
.markdown-body h5:hover .anchor .octicon-link,
.markdown-body h6:hover .anchor .octicon-link {
	visibility: visible;
}

.markdown-body h1 {
	padding-bottom: 0.3em;
	font-size: 2em;
	border-bottom: 1px solid #eaecef;
}

.markdown-body h2 {
	padding-bottom: 0.3em;
	font-size: 1.5em;
	border-bottom: 1px solid #eaecef;
}

.markdown-body h3 {
	font-size: 1.25em;
}

.markdown-body h4 {
	font-size: 1em;
}

.markdown-body h5 {
	font-size: 0.875em;
}

.markdown-body h6 {
	font-size: 0.85em;
	color: #6a737d;
}

.markdown-body ul,
.markdown-body ol {
	padding-left: 2em;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
	margin-top: 0;
	margin-bottom: 0;
}

.markdown-body li {
	word-wrap: break-all;
}

.markdown-body li>p {
	margin-top: 16px;
}

.markdown-body li+li {
	margin-top: 0.25em;
}

.markdown-body dl {
	padding: 0;
}

.markdown-body dl dt {
	padding: 0;
	margin-top: 16px;
	font-size: 1em;
	font-style: italic;
	font-weight: 600;
}

.markdown-body dl dd {
	padding: 0 16px;
	margin-bottom: 16px;
}

.markdown-body table {
	display: block;
	width: 100%;
	overflow: auto;
}

.markdown-body table th {
	font-weight: 600;
}

.markdown-body table th,
.markdown-body table td {
	padding: 6px 13px;
	border: 1px solid #dfe2e5;
}

.markdown-body table tr {
	background-color: #fff;
	border-top: 1px solid #c6cbd1;
}

.markdown-body table tr:nth-child(2n) {
	background-color: #f6f8fa;
}

.markdown-body img {
	max-width: 100%;
	box-sizing: content-box;
	background-color: #fff;
}

.markdown-body img[align=right] {
	padding-left: 20px;
}

.markdown-body img[align=left] {
	padding-right: 20px;
}

.markdown-body code {
	padding: 0.2em 0.4em;
	margin: 0;
	font-size: 85%;
	background-color: rgba(27,31,35,0.05);
	border-radius: 3px;
}

.markdown-body pre {
	word-wrap: normal;
}

.markdown-body pre>code {
	padding: 0;
	margin: 0;
	font-size: 100%;
	word-break: normal;
	white-space: pre;
	background: transparent;
	border: 0;
}

.markdown-body .highlight {
	margin-bottom: 16px;
}

.markdown-body .highlight pre {
	margin-bottom: 0;
	word-break: normal;
}

.markdown-body .highlight pre,
.markdown-body pre {
	padding: 16px;
	overflow: auto;
	font-size: 85%;
	line-height: 1.45;
	background-color: #f6f8fa;
	border-radius: 3px;
}

.markdown-body pre code {
	display: inline;
	max-width: auto;
	padding: 0;
	margin: 0;
	overflow: visible;
	line-height: inherit;
	word-wrap: normal;
	background-color: transparent;
	border: 0;
}

.markdown-body .full-commit .btn-outline:not(:disabled):hover {
	color: #005cc5;
	border-color: #005cc5;
}

.markdown-body kbd {
	display: inline-block;
	padding: 3px 5px;
	font: 11px "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace;
	line-height: 10px;
	color: #444d56;
	vertical-align: middle;
	background-color: #fafbfc;
	border: solid 1px #d1d5da;
	border-bottom-color: #c6cbd1;
	border-radius: 3px;
	box-shadow: inset 0 -1px 0 #c6cbd1;
}

.markdown-body :checked+.radio-label {
	position: relative;
	z-index: 1;
	border-color: #0366d6;
}

.markdown-body .task-list-item {
	list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
	margin-top: 3px;
}

.markdown-body .task-list-item input {
	margin: 0 0.2em 0.25em -1.6em;
	vertical-align: middle;
}

.markdown-body hr {
	border-bottom-color: #eee;
}

</style>
<style>
ol {
    display: block;
    list-style-type: decimal;
}
.pagebreak { page-break-before: always; }
.half { height: 200px; }
</style>

<div class="markdown-body">

<style>
.pagebreak { page-break-before: always; }
.half { height: 200px; }
</style>
<style>
.pagebreak { page-break-before: always; }
.half { height: 200px; }
.markdown-body {
    font-size: 12px;
}
.markdown-body td {
    font-size: 12px;
}
</style>

<h1>Lecture 21 - Text Classification Example</h1>

<h2>This Weeks Lab</h2>

<p>Take the text classification example and use it.</p>

<h2>Text Classification Uses</h2>

<ol>
<li>Sentiment Analysis on Product Reviews</li>
<li>Classification of Email as SPAM</li>
<li>Classification of Medical Data - Prediction of Symptoms to Disease</li>
<li>Social Media Text Classification</li>
</ol>

<h2>How CNN works - Convectional Neural Networks</h2>

<h3>Text is split into chunks</h3>

<p>The input may be split into areas as in an image - but this is a text example.
So think of Paris of words, word triplets etc.</p>

<p>This is referedd to as &ldquo;pooling&rdquo; - with an image you may have averages -
with text it is just proximate grouping.</p>

<p><img src="Average-and-max-pooling-operations_W640.jpg" alt="Average-and-max-pooling-operations_W640.jpg" /></p>

<p>Text looks like this</p>

<p><img src="text-down-sample.png" alt="text-down-sample.png" /></p>

<h3>network is built out of layers that recognize chunks</h3>

<p><img src="Diagram-for-Auto-encoder-The-encoder-and-decoder-transition-can-be-represented-with_W640.jpg" alt="Diagram-for-Auto-encoder-The-encoder-and-decoder-transition-can-be-represented-with_W640.jpg" /></p>

<p><img src="The-overall-architecture-of-the-Convolutional-Neural-Network-CNN-includes-an-input.png" alt="The-overall-architecture-of-the-Convolutional-Neural-Network-CNN-includes-an-input.png" /></p>

<h2>Text Classification Example</h2>

<pre><code>  1: # ----------------------------------------------------------------------------
  2: # Setup
  3: # ----------------------------------------------------------------------------
  4: import matplotlib.pyplot as plt
  5: import os
  6: import re
  7: import shutil
  8: import string
  9: import tensorflow as tf
 10: 
 11: from tensorflow.keras import layers
 12: from tensorflow.keras import losses
 13: 
 14: print(tf.__version__)
 15: 
 16: 
 17: # ----------------------------------------------------------------------------
 18: # Get data.
 19: # ----------------------------------------------------------------------------
 20: 
 21: # Location to pull data from
 22: 
 23: url = &quot;https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz&quot;
 24: 
 25: dataset = tf.keras.utils.get_file(&quot;aclImdb_v1&quot;,
 26:     url,
 27:     untar=True, cache_dir='.',
 28:     cache_subdir='')
 29: 
 30: dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')
 31: print ( os.listdir(dataset_dir) )
 32: 
 33: 
 34: 
 35: train_dir = os.path.join(dataset_dir, 'train')
 36: print ( os.listdir(train_dir) )
 37: 
 38: 
 39: sample_file = os.path.join(train_dir, 'pos/1181_9.txt')
 40: with open(sample_file) as f:
 41:     print(f.read())
 42: 
 43: 
 44: # Discard data we are not using.
 45: remove_dir = os.path.join(train_dir, 'unsup')
 46: shutil.rmtree(remove_dir)
 47: 
 48: 
 49: # ----------------------------------------------------------------------------
 50: # xyzzy
 51: # ----------------------------------------------------------------------------
 52: 
 53: batch_size = 32
 54: seed = 42
 55: 
 56: raw_train_ds = tf.keras.utils.text_dataset_from_directory(
 57:     'aclImdb/train',
 58:     batch_size=batch_size,
 59:     validation_split=0.2,
 60:     subset='training',
 61:     seed=seed)
 62: 
 63: for text_batch, label_batch in raw_train_ds.take(1):
 64:     for i in range(3):
 65:         print(&quot;Review&quot;, text_batch.numpy()[i])
 66:         print(&quot;Label&quot;, label_batch.numpy()[i])
 67: 
 68: print(&quot;Label 0 corresponds to&quot;, raw_train_ds.class_names[0])
 69: print(&quot;Label 1 corresponds to&quot;, raw_train_ds.class_names[1])
 70: 
 71: 
 72: 
 73: # ----------------------------------------------------------------------------
 74: # xyzzy
 75: # ----------------------------------------------------------------------------
 76: 
 77: raw_val_ds = tf.keras.utils.text_dataset_from_directory(
 78:     'aclImdb/train',
 79:     batch_size=batch_size,
 80:     validation_split=0.2,
 81:     subset='validation',
 82:     seed=seed)
 83: 
 84: raw_test_ds = tf.keras.utils.text_dataset_from_directory(
 85:     'aclImdb/test',
 86:     batch_size=batch_size)
 87: 
 88: 
 89: def custom_standardization(input_data):
 90:     lowercase = tf.strings.lower(input_data)
 91:     stripped_html = tf.strings.regex_replace(lowercase, '&lt;br /&gt;', ' ')
 92:     return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), '')
 93: 
 94: 
 95: # ----------------------------------------------------------------------------
 96: # pooling of data
 97: # ----------------------------------------------------------------------------
 98: 
 99: max_features = 10000
100: sequence_length = 250
101: 
102: vectorize_layer = layers.TextVectorization(
103:     standardize=custom_standardization,
104:     max_tokens=max_features,
105:     output_mode='int',
106:     output_sequence_length=sequence_length)
107: 
108: # Make a text-only dataset (without labels), then call adapt
109: train_text = raw_train_ds.map(lambda x, y: x)
110: vectorize_layer.adapt(train_text)
111: 
112: 
113: 
114: def vectorize_text(text, label):
115:     text = tf.expand_dims(text, -1)
116:     return vectorize_layer(text), label
117: 
118: 
119: # retrieve a batch (of 32 reviews and labels) from the dataset
120: text_batch, label_batch = next(iter(raw_train_ds))
121: first_review, first_label = text_batch[0], label_batch[0]
122: print(&quot;Review&quot;, first_review)
123: print(&quot;Label&quot;, raw_train_ds.class_names[first_label])
124: print(&quot;Vectorized review&quot;, vectorize_text(first_review, first_label))
125: 
126: 
127: print(&quot;1287 ---&gt; &quot;,vectorize_layer.get_vocabulary()[1287])
128: print(&quot; 313 ---&gt; &quot;,vectorize_layer.get_vocabulary()[313])
129: print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))
130: 
131: 
132: 
133: # ----------------------------------------------------------------------------
134: # Setup Training / Testing Data
135: # ----------------------------------------------------------------------------
136: 
137: 
138: train_ds = raw_train_ds.map(vectorize_text)
139: val_ds = raw_val_ds.map(vectorize_text)
140: test_ds = raw_test_ds.map(vectorize_text)
141: 
142: 
143: 
144: AUTOTUNE = tf.data.AUTOTUNE
145: 
146: train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)
147: val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
148: test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)
149: 
150: 
151: embedding_dim = 16
152: 
153: 
154: # ----------------------------------------------------------------------------
155: # Multi Layer Model
156: # ----------------------------------------------------------------------------
157: 
158: model = tf.keras.Sequential([
159:     layers.Embedding(max_features + 1, embedding_dim),
160:     layers.Dropout(0.2),
161:     layers.GlobalAveragePooling1D(),
162:     layers.Dropout(0.2),
163:     layers.Dense(1)])
164: 
165: model.summary()
166: 
167: 
168: model.compile(loss=losses.BinaryCrossentropy(from_logits=True),
169:               optimizer='adam',
170:               metrics=tf.metrics.BinaryAccuracy(threshold=0.0))
171: 
172: 
173: 
174: 
175: # ----------------------------------------------------------------------------
176: # Train Model
177: # ----------------------------------------------------------------------------
178: 
179: epochs = 10
180: history = model.fit(
181:     train_ds,
182:     validation_data=val_ds,
183:     epochs=epochs)
184: 
185: 
186: 
187: # ----------------------------------------------------------------------------
188: # Evaluate Model
189: # ----------------------------------------------------------------------------
190: 
191: loss, accuracy = model.evaluate(test_ds)
192: 
193: print(&quot;Loss: &quot;, loss)
194: print(&quot;Accuracy: &quot;, accuracy)
195: 
196: 
197: history_dict = history.history
198: history_dict.keys()
199: 
200: 
201: 
202: # Review results of Training
203: 
204: 
205: acc = history_dict['binary_accuracy']
206: val_acc = history_dict['val_binary_accuracy']
207: loss = history_dict['loss']
208: val_loss = history_dict['val_loss']
209: 
210: epochs = range(1, len(acc) + 1)
211: 
212: # &quot;bo&quot; is for &quot;blue dot&quot;
213: plt.plot(epochs, loss, 'bo', label='Training loss')
214: # b is for &quot;solid blue line&quot;
215: plt.plot(epochs, val_loss, 'b', label='Validation loss')
216: plt.title('Training and validation loss')
217: plt.xlabel('Epochs')
218: plt.ylabel('Loss')
219: plt.legend()
220: 
221: plt.show()
222: 
223: 
224: 
225: 
226: 
227: plt.plot(epochs, acc, 'bo', label='Training acc')
228: plt.plot(epochs, val_acc, 'b', label='Validation acc')
229: plt.title('Training and validation accuracy')
230: plt.xlabel('Epochs')
231: plt.ylabel('Accuracy')
232: plt.legend(loc='lower right')
233: 
234: plt.show()
235: 
236: 
237: # ----------------------------------------------------------------------------
238: # Export Model so we can use it.
239: # ----------------------------------------------------------------------------
240: 
241: export_model = tf.keras.Sequential([
242:     vectorize_layer,
243:     model,
244:     layers.Activation('sigmoid')
245: ])
246: 
247: export_model.compile(
248:     loss=losses.BinaryCrossentropy(from_logits=False), optimizer=&quot;adam&quot;, metrics=['accuracy']
249: )
250: 
251: # Test it with `raw_test_ds`, which yields raw strings
252: loss, accuracy = export_model.evaluate(raw_test_ds)
253: print(accuracy)
254: 
255: 
256: 
257: 
258: # ----------------------------------------------------------------------------
259: # Test with new data.
260: # ----------------------------------------------------------------------------
261: 
262: examples = [
263:     &quot;The movie was great!&quot;,
264:     &quot;The movie was okay.&quot;,
265:     &quot;The movie was terrible...&quot;,
266:     &quot;The best time ever&quot;,
267:     &quot;Horrid waste of time&quot;
268: ]
269: 
270: print ( export_model.predict(examples) )

</code></pre>

</div>

